### 如何保证消息一定能到达消费者？

答: 此案例为单一架构，消息丢失的可能性并不大。若为微服务架构，必须使用可靠消息服务（例如 rocketMQ）保证消息的可靠传输，此外由于秒杀消息可能多次传输，下游服务需要确保消息消费的幂等性（此案例中，实际事务操作前会检查一次是否已有重复订单）。

### 单架构的瓶颈在哪里？做成分布式大概应该怎么做？

答：瓶颈在于数据的读写访问，秒杀场景也是读多写少的场景，所以重点考虑读的扩展性，主要通过分库分摊读请求实现。

### 各种数据库和缓存双写一致性方案比较

#### 先更新数据库，再更新缓存

普遍反对的一种方案，原因：
1. 线程安全角度。同时两条线程写会造成脏数据（缓存更新的时序未必与数据库更新时序相同）；
2. 业务场景角度。如果写多读少，数据压根没读到而缓存频繁被更新，浪费性能；如果写入数据时需要复杂的计算再写入缓存，每次写入都要更新也会对性能有影响，应该直接删除；

#### 先删缓存，再更新数据库

考虑以下情形：

（1）请求A进行写操作，删除缓存；

（2）请求B查询发现缓存不存在；

（3）请求B去数据库查询得到旧值；

（4）请求B将旧值写入缓存；

（5）请求A将新值写入数据库；

如果缓存没有时限，那么缓存中将永远是脏数据。

初步解决方案：延时双删

```java
public void write(String key, Object data) {
    redis.delKey(key);
    db.updateData(data);
    Thread.sleep(1000);
    redis.delKey(key); // 休眠 1 秒再次淘汰缓存
}
```

但还是会有很多问题，比如吞吐量损失，删除失败等等；

#### 先更新数据库，再删缓存

即为经典的 Cache Aside Pattern，但这种方案也会有并发问题，考虑以下情形：

（1）缓存刚好失效；

（2）请求A查询数据库，得一个旧值；

（3）请求B将新值写入数据库；

（4）请求B删除缓存；

（5）请求A将查到的旧值写入缓存；

这种情况需要数据库写操作比读操作更快，发生的概率非常小，此外如果缓存设有缓存时间或者使用类似前面提到的延时双删策略，基本能保证最终一致性。

那缓存删除失败怎么办？

方案1：使用消息队列作为保障重试机制，可以解决问题，但会对业务代码造成大量的侵入。

方案2：独立出一部分非业务代码，订阅数据库的 binlog，每次 binlog 更新获取对应的 key 进行基于消息队列的保障重试。具体轮子为阿里的 canal。


